<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real Motion Detection with Augmented Overlays</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #000;
            color: #fff;
        }
        h1 {
            color: #fff;
            margin-top: 20px;
        }
        .container {
            position: relative;
            width: 800px;
            max-width: 100%;
            height: 450px;
            overflow: hidden;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        canvas {
            pointer-events: none;
            z-index: 10;
        }
    </style>
</head>
<body>
    <h1>Real Motion Detection: Do We Own Ourselves?</h1>
    <div class="container">
        <!-- Live YouTube Stream -->
        <iframe 
            src="https://www.youtube.com/embed/h2HXup8nA1I?si=hoztKe88XDjWrNpQ" 
            width="800" 
            height="450" 
            frameborder="0" 
            allowfullscreen></iframe>
        
        <!-- Overlay Canvas -->
        <canvas id="overlay"></canvas>
    </div>

    <!-- TensorFlow.js and Pose Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <script>
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');

        canvas.width = canvas.parentElement.clientWidth;
        canvas.height = canvas.parentElement.clientHeight;

        // Initialize Pose Detection Model
        async function loadPoseModel() {
            const detectorConfig = {
                modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,
            };
            const detector = await poseDetection.createDetector(
                poseDetection.SupportedModels.MoveNet,
                detectorConfig
            );
            return detector;
        }

        async function detectPose(detector) {
            const video = document.createElement('video');
            video.srcObject = await navigator.mediaDevices.getUserMedia({
                video: true,
            });
            video.play();

            video.addEventListener('loadeddata', async () => {
                while (true) {
                    const poses = await detector.estimatePoses(video);

                    ctx.clearRect(0, 0, canvas.width, canvas.height);

                    poses.forEach(pose => {
                        // Draw keypoints and augment data
                        pose.keypoints.forEach(keypoint => {
                            const { x, y, score } = keypoint;
                            if (score > 0.5) {
                                ctx.beginPath();
                                ctx.arc(x, y, 5, 0, 2 * Math.PI);
                                ctx.fillStyle = 'red';
                                ctx.fill();

                                // Display augmented info near keypoints
                                ctx.fillStyle = 'white';
                                ctx.fillText('Analyzing...', x + 10, y - 10);
                            }
                        });
                    });

                    await tf.nextFrame();
                }
            });
        }

        (async () => {
            const detector = await loadPoseModel();
            detectPose(detector);
        })();
    </script>
</body>
</html>
