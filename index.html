<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MoveNet Multipose Debugging</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #000;
            color: #fff;
        }
        h1 {
            margin-bottom: 20px;
        }
        .container {
            position: relative;
            width: 1200px;
            height: 675px;
            max-width: 100%;
            border: 2px solid #fff;
        }
        iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        canvas {
            z-index: 10;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <h1>Debugging MoveNet Multipose Detection</h1>
    <button id="startCapture">Start Detection</button>
    <div class="container">
        <iframe 
            src="https://www.youtube.com/embed/VVBU63T23j8?autoplay=1&mute=1"
            title="YouTube Live Stream"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen>
        </iframe>
        <video id="capturedVideo" autoplay muted playsinline></video>
        <canvas id="overlay"></canvas>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <script>
        const startCaptureButton = document.getElementById('startCapture');
        const videoElement = document.getElementById('capturedVideo');
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');

        canvas.width = canvas.parentElement.clientWidth;
        canvas.height = canvas.parentElement.clientHeight;

        async function startScreenCapture() {
            try {
                const stream = await navigator.mediaDevices.getDisplayMedia({
                    video: { width: 1920, height: 1080, frameRate: 30 },
                });

                videoElement.srcObject = stream;

                videoElement.onloadeddata = () => console.log("Video feed loaded successfully");

                startMultiposeDetection(videoElement);
            } catch (err) {
                console.error("Error accessing screen capture:", err);
            }
        }

        async function startMultiposeDetection(video) {
            const detectorConfig = { modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING };
            const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);
            console.log("MoveNet Multipose Model Loaded");

            async function detectFrame() {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                console.log("Canvas cleared");

                // Draw video feed for debugging
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                const poses = await detector.estimatePoses(video);
                console.log("Poses detected:", poses);

                poses.forEach((pose, index) => {
                    if (pose.keypoints) {
                        drawPoseWithAugmentedData(pose, index);
                    }
                });

                requestAnimationFrame(detectFrame);
            }

            detectFrame();
        }

        function drawPoseWithAugmentedData(pose, index) {
            const keypoints = pose.keypoints.filter(kp => kp.score > 0.5);

            if (keypoints.length > 0) {
                const minX = Math.min(...keypoints.map(kp => kp.x));
                const minY = Math.min(...keypoints.map(kp => kp.y));
                const maxX = Math.max(...keypoints.map(kp => kp.x));
                const maxY = Math.max(...keypoints.map(kp => kp.y));

                ctx.strokeStyle = "red";
                ctx.lineWidth = 2;
                ctx.strokeRect(minX, minY, maxX - minX, maxY - minY);

                const fakeData = {
                    heartRate: `${Math.floor(Math.random() * 40) + 60} bpm`,
                    stressLevel: ["Low", "Moderate", "High"][Math.floor(Math.random() * 3)],
                    emotion: ["Happy", "Neutral", "Anxious"][Math.floor(Math.random() * 3)],
                };

                ctx.fillStyle = "white";
                ctx.font = "14px Arial";
                ctx.fillText(`Person ${index + 1}`, minX, minY - 55);
                ctx.fillText(`Heart Rate: ${fakeData.heartRate}`, minX, minY - 40);
                ctx.fillText(`Stress Level: ${fakeData.stressLevel}`, minX, minY - 25);
                ctx.fillText(`Emotion: ${fakeData.emotion}`, minX, minY - 10);
            }

            keypoints.forEach(({ x, y }) => {
                ctx.beginPath();
                ctx.arc(x, y, 5, 0, 2 * Math.PI);
                ctx.fillStyle = "blue";
                ctx.fill();
            });

            console.log("Drawing pose for person:", index);
        }

        startCaptureButton.addEventListener('click', startScreenCapture);
    </script>
</body>
</html>
